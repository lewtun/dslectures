{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core library\n",
    "\n",
    "> Helper functions used throughout the lessons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from nbdev.showdoc import *\n",
    "import wget\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "def get_dataset(dataset_name: str):\n",
    "    \"\"\"\n",
    "    Download datasets from Google Drive.\n",
    "    \"\"\"\n",
    "\n",
    "    name_to_id = {\n",
    "        \"word2vec-google-news-300.pkl\": \"1dRwSXbFTcQbn8c3V24G92wFY4DXZ1SDt\",\n",
    "        \"imdb.csv\": \"1wF0YEmQOwceJz2d6w4CfhBgydU87dPGl\",\n",
    "        \"housing.csv\": \"1d7oOKdDmZFx8wf0c8OfuTW1FpUyJHABh\",\n",
    "        \"housing_gmaps_data_raw.csv\": \"1R1RUHAXxzrIngRJMFwyp4vZRVICd-I6T\",\n",
    "        \"housing_addresses.csv\": \"1mOK0uyRz5Zs-Qo7mVMlxwtb2xn1E6N9Q\",\n",
    "        \"housing_merged.csv\": \"1bdYuBtIPrKiU-ut2MeSSsL47onPtZrRt\"\n",
    "    }\n",
    "\n",
    "    path = '../data/'\n",
    "    gdrive_path = \"https://docs.google.com/uc?export=download&id=\"\n",
    "    if dataset_name in name_to_id:\n",
    "        if os.path.exists(path + dataset_name):\n",
    "            print(f\"Dataset already exists at '{path + dataset_name}' and is not downloaded again.\")\n",
    "            return\n",
    "        try:\n",
    "            file_url =  gdrive_path + name_to_id[dataset_name]\n",
    "            wget.download(file_url, out=path)\n",
    "        except Exception as e:\n",
    "            print(\"Something went wrong during download. Try again.\")\n",
    "            raise e\n",
    "        print(f\"Download of {dataset_name} dataset complete.\")\n",
    "    else:\n",
    "        raise KeyError(\"File not on Google Drive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### California Housing Prices\n",
    "This dataset from Kaggle ([link](https://www.kaggle.com/camnugent/california-housing-prices)) is used in the second chapter of Aurélien Géron's recent book *Hands-On Machine learning with Scikit-Learn and TensorFlow*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `housing.csv`\n",
    "This dataset pertains to the houses found in a given California district and some summary stats about them based on the 1990 census data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download of housing.csv dataset complete.\n"
     ]
    }
   ],
   "source": [
    "get_dataset('housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `housing_gmaps_data_raw.csv`\n",
    "This dataset contains the raw outputs of the addresses associated with the coordinates in the `housing.csv` dataset as retrieved with the Google Maps API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download of housing_gmaps_data_raw.csv dataset complete.\n"
     ]
    }
   ],
   "source": [
    "get_dataset('housing_gmaps_data_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `housing_addresses.csv`\n",
    "The `housing_addresses.csv` dataset is a cleaned subset of the `housing_gmaps_data_raw.csv` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download of housing_addresses.csv dataset complete.\n"
     ]
    }
   ],
   "source": [
    "get_dataset('housing_addresses.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### housing_merged.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The merge of `housing.csv` and `housing_addresses.csv` from lesson 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download of housing_merged.csv dataset complete.\n"
     ]
    }
   ],
   "source": [
    "get_dataset('housing_merged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `imdb.csv`\n",
    "The IMDB dataset is available on Kaggle ([link](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)). This is a dataset for binary sentiment classification and provides a set of 25,000 highly polar movie reviews for training and 25,000 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download of imdb.csv dataset complete.\n"
     ]
    }
   ],
   "source": [
    "get_dataset('imdb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `word2vec-google-news-300.pkl`\n",
    "\n",
    "Pre-trained vectors trained on a part of the Google News dataset (about 100 billion words). The model contains 300-dimensional vectors for 3 million words and phrases. The phrases were obtained using a simple data-driven approach described in *Distributed Representations of Words and Phrases and their Compositionality*. This dataset is available from GENSIM ([link](https://github.com/RaRe-Technologies/gensim-data))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download of word2vec-google-news-300.pkl dataset complete.\n"
     ]
    }
   ],
   "source": [
    "get_dataset('word2vec-google-news-300.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
